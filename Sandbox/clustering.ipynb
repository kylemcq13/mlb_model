{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statcast Clustering\n",
    "\n",
    "Objective: Experiment with various clustering techniques (Kmeans/DBscan) to cluster MLB pitch types. \n",
    "\n",
    "Data: Statcast data scraped into postgresql database on a weekly basis.\n",
    "\n",
    "Algorithms: Kmeans/DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from configparser import ConfigParser\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish sql engine connection\n",
    "parser = ConfigParser()\n",
    "parser.read('nb.ini')\n",
    "conn_string = parser.get('my_db', 'conn_string')\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fetch statcast data from postgresql database\n",
    "\n",
    "def get_sql_data(engine):\n",
    "\n",
    "    sql1 = '''\n",
    "        SELECT *\n",
    "        FROM statcast_2016\n",
    "    '''\n",
    "    sc_16 = pd.read_sql_query(sql1, engine)\n",
    "\n",
    "    sql2 = '''\n",
    "        SELECT *\n",
    "        FROM statcast_2017\n",
    "    '''\n",
    "    sc_17 = pd.read_sql_query(sql2, engine)\n",
    "\n",
    "    sql3 = '''\n",
    "        SELECT *\n",
    "        FROM statcast_2018\n",
    "    '''\n",
    "\n",
    "    sc_18 = pd.read_sql_query(sql3, engine)\n",
    "\n",
    "    sql4 = '''\n",
    "        SELECT *\n",
    "        FROM statcast_2019\n",
    "    '''\n",
    "\n",
    "    sc_19 = pd.read_sql_query(sql4, engine)\n",
    "\n",
    "    sql5 = '''\n",
    "        SELECT *\n",
    "        FROM statcast_2020\n",
    "    '''\n",
    "\n",
    "    sc_20 = pd.read_sql_query(sql5, engine)\n",
    "\n",
    "    sql6 = '''\n",
    "        SELECT *\n",
    "        FROM statcast_2021\n",
    "    '''\n",
    "\n",
    "    sc_21 = pd.read_sql_query(sql6, engine)\n",
    "\n",
    "    statcast = pd.concat([sc_16, sc_17, sc_18, sc_19, sc_20, sc_21])\n",
    "\n",
    "    statcast['events']=statcast['events'].fillna('none')\n",
    "    statcast['launch_speed']=statcast['launch_speed'].fillna(0)\n",
    "    statcast['launch_angle']=statcast['launch_angle'].fillna(0)\n",
    "\n",
    "    return statcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "statcast = get_sql_data(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-4a6c51819b04>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_cluster['pitcher_team'] = sc_cluster.apply(pitcher_team, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# filter only relevant columns\n",
    "cols = ['player_name', 'home_team', 'away_team', 'inning_topbot', 'p_throws', 'pitch_type', 'game_date', 'events', 'pitcher', \n",
    "         'batter', 'description', 'launch_speed', 'launch_angle', 'release_speed', 'release_pos_x', \n",
    "         'release_pos_y', 'release_pos_z', 'release_spin_rate', 'release_extension', 'pfx_x', 'pfx_z', \n",
    "         'plate_x', 'plate_z', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'effective_speed',\n",
    "         'pitch_name', 'spin_axis', 'delta_run_exp']\n",
    "\n",
    "sc_cluster = statcast[cols]\n",
    "\n",
    "# assign pitcher teams\n",
    "def pitcher_team(row):\n",
    "\n",
    "\tif row['inning_topbot'] == 'Top':\n",
    "\t\treturn row['home_team']\n",
    "\t\n",
    "\tif row['inning_topbot'] == 'Bot':\n",
    "\t\treturn row['away_team']\n",
    "\n",
    "sc_cluster['pitcher_team'] = sc_cluster.apply(pitcher_team, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-86efd213af1d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_cluster['pitch_type'] = sc_cluster['pitch_type'].replace(['FA'],'FF')\n",
      "<ipython-input-11-86efd213af1d>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sc_cluster['cat'] = np.select(conditions, values)\n"
     ]
    }
   ],
   "source": [
    "# Fastballs and Four Seam Fastballs are the same thing\n",
    "# Group pitches into similar moving pitches: Fastballs, Moving Fastballs, Slider/Cutter, Curve and Off Speed\n",
    "\n",
    "sc_cluster['pitch_type'] = sc_cluster['pitch_type'].replace(['FA'],'FF')\n",
    "\n",
    "# categorize the pitches according to pitcher handedness and pitch type\n",
    "\n",
    "conditions = [\n",
    "    ((sc_cluster['p_throws'] == 'R') & (sc_cluster['pitch_type'] == 'FF')),\n",
    "    ((sc_cluster['p_throws'] == 'R') & (sc_cluster['pitch_type'] == 'FT') | (sc_cluster['p_throws']=='R') & (sc_cluster['pitch_type']=='SI')),\n",
    "    ((sc_cluster['p_throws'] == 'R') & (sc_cluster['pitch_type'] == 'SL') | (sc_cluster['p_throws']=='R') & (sc_cluster['pitch_type']=='FC')),\n",
    "    ((sc_cluster['p_throws'] == 'R') & (sc_cluster['pitch_type'] == 'CU') | (sc_cluster['p_throws']=='R') & (sc_cluster['pitch_type']=='KC')),\n",
    "    ((sc_cluster['p_throws'] == 'R') & (sc_cluster['pitch_type'] == 'CH') | (sc_cluster['p_throws']=='R') & (sc_cluster['pitch_type']=='FS')),\n",
    "    ((sc_cluster['p_throws'] == 'L') & (sc_cluster['pitch_type'] == 'FF')),\n",
    "    ((sc_cluster['p_throws'] == 'L') & (sc_cluster['pitch_type'] == 'FT') | (sc_cluster['p_throws']=='L') & (sc_cluster['pitch_type']=='SI')),\n",
    "    ((sc_cluster['p_throws'] == 'L') & (sc_cluster['pitch_type'] == 'SL') | (sc_cluster['p_throws']=='L') & (sc_cluster['pitch_type']=='FC')),\n",
    "    ((sc_cluster['p_throws'] == 'L') & (sc_cluster['pitch_type'] == 'CU') | (sc_cluster['p_throws']=='L') & (sc_cluster['pitch_type']=='KC')),\n",
    "    ((sc_cluster['p_throws'] == 'L') & (sc_cluster['pitch_type'] == 'CH') | (sc_cluster['p_throws']=='L') & (sc_cluster['pitch_type']=='FS'))\n",
    "    ]\n",
    "\n",
    "values = ['rhp_ff', 'rhp_mf', 'rhp_slct', 'rhp_cukc', 'rhp_off', 'lhp_ff', 'lhp_mf', 'lhp_slct', 'lhp_cukc', 'lhp_off']\n",
    "\n",
    "sc_cluster['cat'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# creating a copy to keep original df as is for later\n",
    "df_clust = sc_cluster.copy()\n",
    "\n",
    "# features to scale\n",
    "cols_scale = [\n",
    "    'release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'spin_axis', 'plate_x', 'plate_z']\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler().fit(df_clust[cols_scale])\n",
    "df_clust[cols_scale] = scaler.transform(df_clust[cols_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nulls\n",
    "\n",
    "rhp_ff = df_clust.loc[df_clust['cat']=='rhp_ff'].dropna()\n",
    "rhp_slct = df_clust.loc[df_clust['cat']=='rhp_slct'].dropna()\n",
    "rhp_off = df_clust.loc[df_clust['cat']=='rhp_off'].dropna()\n",
    "lhp_ff = df_clust.loc[df_clust['cat']=='lhp_ff'].dropna()\n",
    "lhp_mf = df_clust.loc[df_clust['cat']=='lhp_mf'].dropna()\n",
    "lhp_slct = df_clust.loc[df_clust['cat']=='lhp_slct'].dropna()\n",
    "lhp_cukc = df_clust.loc[df_clust['cat']=='lhp_cukc'].dropna()\n",
    "lhp_off = df_clust.loc[df_clust['cat']=='lhp_off'].dropna()\n",
    "\n",
    "\n",
    "df_list = [rhp_ff, rhp_slct, rhp_off, lhp_ff, lhp_mf, lhp_slct, lhp_cukc, lhp_off]\n",
    "\n",
    "for df in df_list:\n",
    "    kmeanModel = KMeans(n_clusters=4)\n",
    "    kmeanModel.fit(df[cols_scale])\n",
    "    df['cluster_id'] = kmeanModel.labels_\n",
    "    df['cluster_id'] = df['cluster_id'].astype('str')\n",
    "    df['cluster_name'] = df['cat'] + '_' + df['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhp_mf = df_clust.loc[df_clust['cat']=='rhp_mf'].dropna()\n",
    "rhp_cukc = df_clust.loc[df_clust['cat']=='rhp_cukc'].dropna()\n",
    "\n",
    "df_list2 = [rhp_mf, rhp_cukc]\n",
    "\n",
    "for df in df_list2:\n",
    "    kmeanModel = KMeans(n_clusters=5)\n",
    "    kmeanModel.fit(df[cols_scale])\n",
    "    df['cluster_id'] = kmeanModel.labels_\n",
    "    df['cluster_id'] = df['cluster_id'].astype('str')\n",
    "    df['cluster_name'] = df['cat'] + '_' + df['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [rhp_mf, rhp_cukc, rhp_ff, rhp_slct, rhp_off, lhp_ff, lhp_mf, lhp_slct, lhp_cukc, lhp_off]\n",
    "\n",
    "clustering = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.to_sql('cluster_df', engine, if_exists='replace', \n",
    "               chunksize= 100, method='multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7743e88522c0656e3c4d76210be5b89a02458a7273f3872c633d8ddda606ff01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
